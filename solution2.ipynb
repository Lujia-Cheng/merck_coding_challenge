{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c43dd6783736ab8b",
   "metadata": {},
   "source": [
    "2. Chromatography is frequently used to determine the outcome of experiments. However, most chromatography instrument manufacturers provide data in proprietary data formats. Weâ€™ve developed the [Rainbow](https://github.com/evanyeyeye/rainbow) package to unlock these files and we want to know whether you can extend Rainbow.\n",
    "\n",
    "[Here](https://drive.google.com/drive/folders/1tyYTM94BdOkCkvZCJ4a1gT5CYYb-EKDj?usp=sharing) are three folders with artificially generated and encoded chromatography data:\n",
    "\n",
    "(a) **pear** challenge (easy): time vs. intensity data\n",
    "\n",
    "(b) **scale** challenge (intermediate): time vs. wavelength vs. absorbance data\n",
    "\n",
    "(c) **sixtysix** (hard): time vs. mass vs. intensity data\n",
    "\n",
    "In each folder, you will find a `sample/` subfolder and `problemX` subfolders (where X=1,2,3). The sample subfolder contains a matched binary/csv pair. You should examine this pair with a hex editor (or any other tool of your choice) to determine its binary organization. The rest of the folders contain only binaries. Your decoding script should run on these files. I will check that the csv output matches what is expected.\n",
    "\n",
    "**Note:** your answers should not include any hard-coded magic numbers (other than the lengths of headers, chunks, footers, etc.)\n",
    "\n",
    "**Please provide a concise and clear explanation for each file structure in markdown format.** What is the format of the header, data, and footer? I suggest writing a couple paragraphs to accompany a table like this:\n",
    "\n",
    "| Location | Length (bytes) | Endianess | format | Value        |\n",
    "|----------|----------------|-----------|--------|--------------|\n",
    "| 0x180    | 4              | big       | uint   | time[0] (ms) |\n",
    "| 0x184    | 4              | little    | uint   | intensity[0] |\n",
    "| ...      |                |           |        |              |\n",
    "\n",
    "Please document your code clearly with comments and docstrings. Please provide your answer as one `.py` file per problem (so, one for pear, one for scale, and one for sixtysix). Please provide the decoded `.csv` files so I can check them against the expected results. Place one decoded csv file per problem directory like this: `pear/problem1/pear.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a9693bb595a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def extract_pear_to_df(input_path, header_size=0x140, footer_size=0x1e0):\n",
    "    \"\"\"\n",
    "    Extracts binary data from a file to a DataFrame.\n",
    "    \n",
    "    :param input_path: Path to the binary file.\n",
    "    :param header_size: Size of the header in bytes.\n",
    "    :param footer_size: Size of the footer in bytes.\n",
    "    :return: DataFrame containing the extracted data.\n",
    "    \"\"\"\n",
    "    col0 = []\n",
    "    col1 = []\n",
    "\n",
    "    with open(input_path, 'rb') as f:\n",
    "        # Skip the header\n",
    "        f.seek(header_size)\n",
    "\n",
    "        # Calculate the size of the body (excluding header and footer)\n",
    "        file_size = os.path.getsize(input_path)\n",
    "        body_size = file_size - header_size - footer_size\n",
    "\n",
    "        # Read the body\n",
    "        bytes_read = 0\n",
    "        while bytes_read < body_size:\n",
    "            # Read 8 bytes (2 columns of 4 bytes each)\n",
    "            chunk = f.read(8)\n",
    "            if len(chunk) < 8:\n",
    "                break\n",
    "\n",
    "            # Extract values from the specified columns\n",
    "            col0_val = struct.unpack('<I', chunk[0:4])[0]\n",
    "            col1_val = struct.unpack('<I', chunk[4:8])[0]\n",
    "\n",
    "            col0.append(col0_val)\n",
    "            col1.append(col1_val)\n",
    "\n",
    "            bytes_read += 8\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({'Time (ms)': col0, 'Intensity': col1})\n",
    "    return df\n",
    "\n",
    "\n",
    "def main(input_path=None, header_size=0x140, footer_size=0x1e0):\n",
    "    \"\"\"\n",
    "    Extracts binary data from a file to a DataFrame and saves it to a CSV file.\n",
    "\n",
    "    :param input_path: Path to the binary file.\n",
    "    :param header_size: Size of the header in bytes.\n",
    "    :param footer_size: Size of the footer in bytes.\n",
    "    \"\"\"\n",
    "    if input_path is None:\n",
    "        input_path = input('Enter the path to the binary file: ')\n",
    "\n",
    "    # Extract the binary data to a DataFrame\n",
    "    df = extract_pear_to_df(input_path, header_size, footer_size)\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(input_path + '.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc94fcdb4489d85",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e6f2b9df3ed9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the header and footer size\n",
    "header_size = 0x140\n",
    "footer_size = 0x1e0\n",
    "file_path = './pear/sample/pear'\n",
    "df = extract_pear_to_df(file_path, header_size, footer_size)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "csv_df = pd.read_csv('./pear/sample/pear.csv')\n",
    "\n",
    "# Compare the DataFrames\n",
    "print(\"DataFrames are equal:\", df.equals(csv_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7feca0594a8e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of file paths\n",
    "file_paths = [\"./pear/problem1/pear\", \"./pear/problem2/pear\",\n",
    "              \"./pear/problem3/pear\"]\n",
    "\n",
    "# Loop through each file path and decode the binary to CSV\n",
    "for p in file_paths:\n",
    "    main(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6dc55fb1ff1cc4",
   "metadata": {},
   "source": [
    "# Scale\n",
    "\n",
    "0.0000,-1,-2,27,23,98,1,48,69,-1,-2093,39,-1,822,1,0,16,40,0\n",
    "0.0004,0,0,26,23,99,1,50,70,-1,-2109,36,-1,830,-1,0,14,40,-1\n",
    "0.0009,-2,1,26,24,100,-1,47,68,-2,-2132,38,-1,835,0,-2,15,40,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eef2486ae022c215",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T22:38:04.771313Z",
     "start_time": "2024-07-26T22:38:04.762836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x39d1b717\n",
      "0x3a6bedfa\n",
      "0x3aaa64c3\n",
      "0x3ec30553\n",
      "0x40a00000\n",
      "0x3f0fec57\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "import binascii\n",
    "\n",
    "\n",
    "def float_to_hex(f):\n",
    "    print(hex(struct.unpack('<I', struct.pack('<f', f))[0]))\n",
    "\n",
    "\n",
    "float_to_hex(0.0004)\n",
    "float_to_hex(0.0009)\n",
    "float_to_hex(0.0013)\n",
    "float_to_hex(0.3809)\n",
    "float_to_hex(5.0000)\n",
    "float_to_hex(0.5622)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f89d33d17ff201",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "line3 -> 0.0004 -> 0x39d1b717 ->  (17 b7 d1 39) -> location: 0x250\n",
    "line4 -> 0.0009 -> 0x3a6bedfa ->  (fa ed 6b 3a) -> location: 0x29e\n",
    "line5 -> 0.0013 -> 0x3aaa64c3 -> (c3 64 aa 3a) -> location: 0x2ec\n",
    "...\n",
    "line-1 -> 5.0000 -> 0x40a00000 ->  (00 00 a0 40) -> location: 0xdb9d6\n",
    "\n",
    "\n",
    "\n",
    "`48 48`\n",
    "\n",
    "line 2: [0.0000,-1,-2,27,23,98,1,48,69,-1,-2093,39,-1,822,1,0,16,40,0]\n",
    "\n",
    "`00 00 00 00 [FF FF FF EC] [FF FF FF D8] 00 00 02 1C 00 00 01 CC 00 00 07 A8 00 00 00 14 00 00 03 C0 00 00 05 64 [FF FF FF EC] FF FF 5C 7C 00 00 03 0C [FF FF FF EC] 00 00 40 38 00 00 00 14 00 00 00 00 00 00 01 40 00 00 03 20 00 00 00 00 [48 48]`\n",
    "\n",
    "line 3: [0.0004,0,0,26,23,99,1,50,70,-1,-2109,36,-1,830,-1,0,14,40,-1]\n",
    "\n",
    "`17 B7 D1 39 00 00 00 00 00 00 00 00 00 00 02 08 00 00 01 CC 00 00 07 BC 00 00 00 14 00 00 03 E8 00 00 05 78 [[FF FF FF EC]] FF FF 5B 3C 00 00 02 D0 [[FF FF FF EC]] 00 00 40 D8 [FF FF FF EC] 00 00 00 00 00 00 01 18 00 00 03 20 [FF FF FF EC] 48 48`\n",
    "\n",
    "line 4: [0.0009,-2,1,26,24,100,-1,47,68,-2,-2132,38,-1,835,0,-2,15,40,0]\n",
    "\n",
    "`FA ED 6B 3A [FF FF FF D8] 00 00 00 14 00 00 02 08 00 00 01 E0 00 00 07 D0 [FF FF FF EC] 00 00 03 AC 00 00 05 50 [FF FF FF D8] FF FF 59 70 00 00 02 F8 [FF FF FF EC] 00 00 41 3C 00 00 00 00 [FF FF FF D8] 00 00 01 2C 00 00 03 20 [00 00 00 00 48 48]` \n",
    "\n",
    "\n",
    "Seems padding is used to align the floats to 4 bytes. The floats are stored in little-endian format.\n",
    "line 3:\n",
    "\n",
    "I'm not sure about the order of the columns. We'll see. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "36b76cc587ad2547",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T23:28:50.895253Z",
     "start_time": "2024-07-26T23:28:50.886147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 0x13ffffffec -1\n",
      "-2 0x13ffffffd8 -2\n",
      "27 0x21c 27\n",
      "23 0x1cc 23\n",
      "98 0x7a8 98\n",
      "1 0x14 1\n",
      "48 0x3c0 48\n",
      "69 0x564 69\n",
      "-1 0x13ffffffec -1\n",
      "-2093 0x13ffff5c7c -2093\n",
      "39 0x30c 39\n",
      "-1 0x13ffffffec -1\n",
      "822 0x4038 822\n",
      "1 0x14 1\n",
      "0 0x0 0\n",
      "16 0x140 16\n",
      "40 0x320 40\n",
      "0 0x0 0\n"
     ]
    }
   ],
   "source": [
    "# negative number is 2-complement, then scale 20 to hex\n",
    "def int_scale_to_hex(i):\n",
    "    if i < 0:\n",
    "        i = 2 ** 32 + i\n",
    "    return hex(i * 20)\n",
    "\n",
    "\n",
    "def hex_to_int_scale(h):\n",
    "    i = int(h, 16) // 20\n",
    "    if i >= 2 ** 31:\n",
    "        i -= 2 ** 32\n",
    "    return i\n",
    "\n",
    "\n",
    "for x in [-1, -2, 27, 23, 98, 1, 48, 69, -1, -2093, 39, -1, 822, 1, 0, 16, 40,\n",
    "          0]:\n",
    "    hex_val = int_scale_to_hex(x)\n",
    "    print(x, hex_val, hex_to_int_scale(hex_val))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c6763eb043673e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T23:30:39.634043Z",
     "start_time": "2024-07-26T23:30:39.622613Z"
    }
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def hex_to_int_scale(h):\n",
    "    i = int(h, 16) // 20\n",
    "    if i >= 2 ** 31:\n",
    "        i -= 2 ** 32\n",
    "    return i\n",
    "\n",
    "\n",
    "def extract_scale_to_df(input_path, header_size=0x200, footer_size=0):\n",
    "    \"\"\"\n",
    "    Extracts binary data from a file to a DataFrame.\n",
    "    \n",
    "    :param input_path: Path to the binary file.\n",
    "    :param header_size: Size of the header in bytes.\n",
    "    :param footer_size: Size of the footer in bytes.\n",
    "    :return: DataFrame containing the extracted data.\n",
    "    \"\"\"\n",
    "    # Initialize columns \n",
    "    columns = [[] for _ in\n",
    "               range(19)]  # Assuming 19 columns based on the provided data\n",
    "\n",
    "    with open(input_path, 'rb') as f:\n",
    "        # Skip the header\n",
    "        f.seek(header_size)\n",
    "\n",
    "        # Calculate the size of the body (excluding header and footer)\n",
    "        file_size = os.path.getsize(input_path)\n",
    "        body_size = file_size - header_size - footer_size\n",
    "\n",
    "        # Read the body\n",
    "        bytes_read = 0\n",
    "\n",
    "        while bytes_read < body_size:\n",
    "            chunk = f.read(78)\n",
    "            if len(chunk) < 78:\n",
    "                break\n",
    "\n",
    "            # Ignore the first 2 padding bytes\n",
    "\n",
    "            # Get first column is hex of float\n",
    "            float_val = struct.unpack('<f', chunk[2:6])[0]\n",
    "            columns[0].append(float_val)\n",
    "\n",
    "            # Extract the rest of the chuck 4 byte at a time, \n",
    "            # convert to hex and then to int\n",
    "            for i in range(1, 19):\n",
    "                hex_val = binascii.hexlify(chunk[6 + (i - 1) * 4: 6 + i * 4])\n",
    "                int_val = hex_to_int_scale(hex_val)\n",
    "                columns[i].append(int_val)\n",
    "                \n",
    "            bytes_read += 78\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({f'Column {i}': col for i, col in enumerate(columns)})\n",
    "    return df\n",
    "\n",
    "\n",
    "def main(input_path=None, header_size=0x200, footer_size=0):\n",
    "    \"\"\"\n",
    "    Extracts binary data from a file to a DataFrame and saves it to a CSV file.\n",
    "\n",
    "    :param input_path: Path to the binary file.\n",
    "    :param header_size: Size of the header in bytes.\n",
    "    :param footer_size: Size of the footer in bytes.\n",
    "    \"\"\"\n",
    "    if input_path is None:\n",
    "        input_path = input('Enter the path to the binary file: ')\n",
    "\n",
    "    # Extract the binary data to a DataFrame\n",
    "    df = extract_scale_to_df(input_path, header_size, footer_size)\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(input_path + '.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8349ab7c09ad8b",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4a3b5af085a8ab4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T23:30:42.667203Z",
     "start_time": "2024-07-26T23:30:42.200368Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'binascii' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m footer_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      3\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./scale/sample/scale\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mextract_scale_to_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfooter_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "Cell \u001b[1;32mIn[1], line 51\u001b[0m, in \u001b[0;36mextract_scale_to_df\u001b[1;34m(input_path, header_size, footer_size)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Extract the rest of the chuck 4 byte at a time, \u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# convert to hex and then to int\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m19\u001b[39m):\n\u001b[1;32m---> 51\u001b[0m     hex_val \u001b[38;5;241m=\u001b[39m \u001b[43mbinascii\u001b[49m\u001b[38;5;241m.\u001b[39mhexlify(chunk[\u001b[38;5;241m6\u001b[39m \u001b[38;5;241m+\u001b[39m (i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m: \u001b[38;5;241m6\u001b[39m \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m])\n\u001b[0;32m     52\u001b[0m     int_val \u001b[38;5;241m=\u001b[39m hex_to_int_scale(hex_val)\n\u001b[0;32m     53\u001b[0m     columns[i]\u001b[38;5;241m.\u001b[39mappend(int_val)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'binascii' is not defined"
     ]
    }
   ],
   "source": [
    "header_size = 0x200\n",
    "footer_size = 0\n",
    "file_path = './scale/sample/scale'\n",
    "df = extract_scale_to_df(file_path, header_size, footer_size)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3408dd2f666488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
